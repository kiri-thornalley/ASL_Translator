{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (27455, 28, 28, 1)\n",
      "x_test shape: (7172, 28, 28, 1)\n",
      "Epoch 1/2\n",
      "215/215 [==============================] - ETA: 0s - loss: 3.0578 - accuracy: 0.0716"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiri/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 440s 2s/step - loss: 3.0578 - accuracy: 0.0716 - val_loss: 2.7585 - val_accuracy: 0.0944 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "215/215 [==============================] - 394s 2s/step - loss: 2.3182 - accuracy: 0.2387 - val_loss: 1.5735 - val_accuracy: 0.4101 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, Flatten, Dense, Dropout\n",
    "import warnings\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Change filepath to local repository\n",
    "df_train, df_test = pd.read_csv('/home/kiri/ASL_Translator/Data/sign_mnist_train/sign_mnist_train.csv'), pd.read_csv('/home/kiri/ASL_Translator/Data/sign_mnist_test/sign_mnist_test.csv')\n",
    "y_train, y_test = df_train['label'], df_test['label']\n",
    "df_train.drop(['label'], axis=1, inplace=True)\n",
    "df_test.drop(['label'], axis=1, inplace=True)\n",
    "# Initialize samples for model\n",
    "x_train = df_train.values.reshape(df_train.shape[0], 28,28,1)\n",
    "x_test = df_test.values.reshape(df_test.shape[0], 28,28,1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "\n",
    "# Generated augmented data\n",
    "dg = ImageDataGenerator(rescale=1./255, zoom_range=0.2, width_shift_range=.2, height_shift_range=.2, rotation_range=30, brightness_range=[0.8, 1.2], horizontal_flip=True)\n",
    "dg_scaled = ImageDataGenerator(rescale=1./255)\n",
    "x_train, x_test = dg.flow(x_train, y_train, batch_size=128), dg_scaled.flow(x_test, y_test)\n",
    "callback_checkpoint = ModelCheckpoint(filepath='best_model.hdf5', save_weights_only=False, monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "callback_lr = ReduceLROnPlateau(monitor='loss', mode='min', min_delta=0.01, patience=3, factor=.75, min_lr=0.00001, verbose=1)\n",
    "\n",
    "\"\"\"\n",
    "Model:\n",
    "3x(Conv2D + Maxpool + Dropout)\n",
    "Flatten\n",
    "3x(Dense Relu)\n",
    "Dense Softmax\n",
    "\"\"\"\n",
    "Model = Sequential(\n",
    "    [Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\", input_shape=(28,28,1)),\n",
    "     MaxPool2D(2, 2, padding='same'), Dropout(0.2),\n",
    "     Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\"),\n",
    "     MaxPool2D(2, 2, padding='same'), Dropout(0.2),\n",
    "     Conv2D(filters=512, kernel_size=(3, 3), activation=\"relu\"),\n",
    "     MaxPool2D(2, 2, padding='same'), Dropout(0.2),\n",
    "     Flatten(),\n",
    "     Dense(units=4096, activation=\"relu\"), Dropout(0.2),\n",
    "     Dense(units=1024, activation=\"relu\"), Dropout(0.2),\n",
    "     Dense(units=256, activation=\"relu\"), Dropout(0.2),\n",
    "     Dense(units=25, activation=\"softmax\"),\n",
    "     ])\n",
    "\n",
    "# Train then extract accuracy, loss, and num epochs\n",
    "Model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = Model.fit(x_train, validation_data=x_test, epochs=2, callbacks=[callback_checkpoint, callback_lr])\n",
    "accuracy, val_accuracy = history.history['accuracy'], history.history['val_accuracy']\n",
    "loss, val_loss = history.history['loss'], history.history['val_loss']\n",
    "epochs_trained = range(len(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
